{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"long_short_term_memory\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " stft_5_input (InputLayer)      [(None, 16000, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " stft_5 (STFT)                  (None, 100, 257, 1)  0           ['stft_5_input[0][0]']           \n",
      "                                                                                                  \n",
      " magnitude_5 (Magnitude)        (None, 100, 257, 1)  0           ['stft_5[0][0]']                 \n",
      "                                                                                                  \n",
      " apply_filterbank_5 (ApplyFilte  (None, 100, 128, 1)  0          ['magnitude_5[0][0]']            \n",
      " rbank)                                                                                           \n",
      "                                                                                                  \n",
      " magnitude_to_decibel_5 (Magnit  (None, 100, 128, 1)  0          ['apply_filterbank_5[0][0]']     \n",
      " udeToDecibel)                                                                                    \n",
      "                                                                                                  \n",
      " batch_norm (LayerNormalization  (None, 100, 128, 1)  256        ['magnitude_to_decibel_5[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " reshape (TimeDistributed)      (None, 100, 128)     0           ['batch_norm[0][0]']             \n",
      "                                                                                                  \n",
      " td_dense_tanh (TimeDistributed  (None, 100, 64)     8256        ['reshape[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_lstm (Bidirectio  (None, 100, 64)     24832       ['td_dense_tanh[0][0]']          \n",
      " nal)                                                                                             \n",
      "                                                                                                  \n",
      " skip_connection (Concatenate)  (None, 100, 128)     0           ['td_dense_tanh[0][0]',          \n",
      "                                                                  'bidirectional_lstm[0][0]']     \n",
      "                                                                                                  \n",
      " dense_1_relu (Dense)           (None, 100, 64)      8256        ['skip_connection[0][0]']        \n",
      "                                                                                                  \n",
      " max_pool_1d (MaxPooling1D)     (None, 50, 64)       0           ['dense_1_relu[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2_relu (Dense)           (None, 50, 32)       2080        ['max_pool_1d[0][0]']            \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1600)         0           ['dense_2_relu[0][0]']           \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1600)         0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3_relu (Dense)           (None, 32)           51232       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " softmax (Dense)                (None, 10)           330         ['dense_3_relu[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 95,242\n",
      "Trainable params: 95,242\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 1.0424 - accuracy: 0.6674 - recall_5: 0.5154 - precision_5: 0.8571\n",
      "Epoch 1: val_loss improved from inf to 0.63919, saving model to models\\lstm.h5\n",
      "1038/1038 [==============================] - 19s 16ms/step - loss: 1.0415 - accuracy: 0.6678 - recall_5: 0.5160 - precision_5: 0.8575 - val_loss: 0.6392 - val_accuracy: 0.8261 - val_recall_5: 0.7582 - val_precision_5: 0.9012\n",
      "Epoch 2/100\n",
      "1038/1038 [==============================] - ETA: 0s - loss: 0.5149 - accuracy: 0.8583 - recall_5: 0.8019 - precision_5: 0.9215\n",
      "Epoch 2: val_loss improved from 0.63919 to 0.51148, saving model to models\\lstm.h5\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.5149 - accuracy: 0.8583 - recall_5: 0.8019 - precision_5: 0.9215 - val_loss: 0.5115 - val_accuracy: 0.8587 - val_recall_5: 0.8174 - val_precision_5: 0.9143\n",
      "Epoch 3/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.3652 - accuracy: 0.9040 - recall_5: 0.8704 - precision_5: 0.9450\n",
      "Epoch 3: val_loss improved from 0.51148 to 0.35126, saving model to models\\lstm.h5\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.3652 - accuracy: 0.9040 - recall_5: 0.8702 - precision_5: 0.9451 - val_loss: 0.3513 - val_accuracy: 0.9065 - val_recall_5: 0.8745 - val_precision_5: 0.9415\n",
      "Epoch 4/100\n",
      "1038/1038 [==============================] - ETA: 0s - loss: 0.2899 - accuracy: 0.9276 - recall_5: 0.9016 - precision_5: 0.9570\n",
      "Epoch 4: val_loss improved from 0.35126 to 0.32501, saving model to models\\lstm.h5\n",
      "1038/1038 [==============================] - 15s 15ms/step - loss: 0.2899 - accuracy: 0.9276 - recall_5: 0.9016 - precision_5: 0.9570 - val_loss: 0.3250 - val_accuracy: 0.9098 - val_recall_5: 0.8864 - val_precision_5: 0.9401\n",
      "Epoch 5/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.2390 - accuracy: 0.9394 - recall_5: 0.9215 - precision_5: 0.9606\n",
      "Epoch 5: val_loss improved from 0.32501 to 0.29684, saving model to models\\lstm.h5\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.2392 - accuracy: 0.9394 - recall_5: 0.9214 - precision_5: 0.9607 - val_loss: 0.2968 - val_accuracy: 0.9228 - val_recall_5: 0.9071 - val_precision_5: 0.9456\n",
      "Epoch 6/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.2048 - accuracy: 0.9523 - recall_5: 0.9362 - precision_5: 0.9687\n",
      "Epoch 6: val_loss improved from 0.29684 to 0.28507, saving model to models\\lstm.h5\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.2048 - accuracy: 0.9522 - recall_5: 0.9362 - precision_5: 0.9687 - val_loss: 0.2851 - val_accuracy: 0.9245 - val_recall_5: 0.9049 - val_precision_5: 0.9509\n",
      "Epoch 7/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.1722 - accuracy: 0.9596 - recall_5: 0.9477 - precision_5: 0.9734\n",
      "Epoch 7: val_loss improved from 0.28507 to 0.25330, saving model to models\\lstm.h5\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.1721 - accuracy: 0.9596 - recall_5: 0.9478 - precision_5: 0.9734 - val_loss: 0.2533 - val_accuracy: 0.9326 - val_recall_5: 0.9234 - val_precision_5: 0.9518\n",
      "Epoch 8/100\n",
      "1035/1038 [============================>.] - ETA: 0s - loss: 0.1503 - accuracy: 0.9665 - recall_5: 0.9564 - precision_5: 0.9766\n",
      "Epoch 8: val_loss did not improve from 0.25330\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.1509 - accuracy: 0.9664 - recall_5: 0.9563 - precision_5: 0.9765 - val_loss: 0.2694 - val_accuracy: 0.9272 - val_recall_5: 0.9163 - val_precision_5: 0.9456\n",
      "Epoch 9/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.1409 - accuracy: 0.9679 - recall_5: 0.9579 - precision_5: 0.9777\n",
      "Epoch 9: val_loss improved from 0.25330 to 0.24491, saving model to models\\lstm.h5\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.1409 - accuracy: 0.9679 - recall_5: 0.9579 - precision_5: 0.9777 - val_loss: 0.2449 - val_accuracy: 0.9255 - val_recall_5: 0.9130 - val_precision_5: 0.9433\n",
      "Epoch 10/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.1186 - accuracy: 0.9757 - recall_5: 0.9669 - precision_5: 0.9834\n",
      "Epoch 10: val_loss did not improve from 0.24491\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.1187 - accuracy: 0.9756 - recall_5: 0.9668 - precision_5: 0.9834 - val_loss: 0.3260 - val_accuracy: 0.9207 - val_recall_5: 0.9120 - val_precision_5: 0.9369\n",
      "Epoch 11/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.1234 - accuracy: 0.9722 - recall_5: 0.9647 - precision_5: 0.9794\n",
      "Epoch 11: val_loss did not improve from 0.24491\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.1235 - accuracy: 0.9720 - recall_5: 0.9645 - precision_5: 0.9793 - val_loss: 0.2792 - val_accuracy: 0.9266 - val_recall_5: 0.9141 - val_precision_5: 0.9407\n",
      "Epoch 12/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.1025 - accuracy: 0.9786 - recall_5: 0.9723 - precision_5: 0.9856\n",
      "Epoch 12: val_loss did not improve from 0.24491\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.1025 - accuracy: 0.9786 - recall_5: 0.9723 - precision_5: 0.9855 - val_loss: 0.2691 - val_accuracy: 0.9391 - val_recall_5: 0.9310 - val_precision_5: 0.9496\n",
      "Epoch 13/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0954 - accuracy: 0.9808 - recall_5: 0.9755 - precision_5: 0.9861\n",
      "Epoch 13: val_loss did not improve from 0.24491\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0954 - accuracy: 0.9808 - recall_5: 0.9755 - precision_5: 0.9861 - val_loss: 0.2706 - val_accuracy: 0.9277 - val_recall_5: 0.9217 - val_precision_5: 0.9443\n",
      "Epoch 14/100\n",
      "1038/1038 [==============================] - ETA: 0s - loss: 0.1067 - accuracy: 0.9762 - recall_5: 0.9704 - precision_5: 0.9823\n",
      "Epoch 14: val_loss did not improve from 0.24491\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.1067 - accuracy: 0.9762 - recall_5: 0.9704 - precision_5: 0.9823 - val_loss: 0.2709 - val_accuracy: 0.9272 - val_recall_5: 0.9174 - val_precision_5: 0.9430\n",
      "Epoch 15/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0941 - accuracy: 0.9805 - recall_5: 0.9752 - precision_5: 0.9853\n",
      "Epoch 15: val_loss did not improve from 0.24491\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0942 - accuracy: 0.9804 - recall_5: 0.9751 - precision_5: 0.9852 - val_loss: 0.2551 - val_accuracy: 0.9408 - val_recall_5: 0.9250 - val_precision_5: 0.9524\n",
      "Epoch 16/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0888 - accuracy: 0.9819 - recall_5: 0.9781 - precision_5: 0.9860\n",
      "Epoch 16: val_loss did not improve from 0.24491\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0888 - accuracy: 0.9819 - recall_5: 0.9781 - precision_5: 0.9860 - val_loss: 0.2650 - val_accuracy: 0.9424 - val_recall_5: 0.9348 - val_precision_5: 0.9524\n",
      "Epoch 17/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0770 - accuracy: 0.9853 - recall_5: 0.9823 - precision_5: 0.9885\n",
      "Epoch 17: val_loss did not improve from 0.24491\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0771 - accuracy: 0.9852 - recall_5: 0.9823 - precision_5: 0.9885 - val_loss: 0.2510 - val_accuracy: 0.9364 - val_recall_5: 0.9299 - val_precision_5: 0.9521\n",
      "Epoch 18/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0829 - accuracy: 0.9829 - recall_5: 0.9788 - precision_5: 0.9872\n",
      "Epoch 18: val_loss did not improve from 0.24491\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0829 - accuracy: 0.9830 - recall_5: 0.9789 - precision_5: 0.9872 - val_loss: 0.2640 - val_accuracy: 0.9370 - val_recall_5: 0.9299 - val_precision_5: 0.9543\n",
      "Epoch 19/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0781 - accuracy: 0.9837 - recall_5: 0.9814 - precision_5: 0.9877\n",
      "Epoch 19: val_loss did not improve from 0.24491\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0781 - accuracy: 0.9837 - recall_5: 0.9814 - precision_5: 0.9878 - val_loss: 0.2642 - val_accuracy: 0.9375 - val_recall_5: 0.9304 - val_precision_5: 0.9474\n",
      "Epoch 20/100\n",
      "1038/1038 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9849 - recall_5: 0.9811 - precision_5: 0.9879\n",
      "Epoch 20: val_loss did not improve from 0.24491\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0764 - accuracy: 0.9849 - recall_5: 0.9811 - precision_5: 0.9879 - val_loss: 0.2457 - val_accuracy: 0.9451 - val_recall_5: 0.9391 - val_precision_5: 0.9558\n",
      "Epoch 21/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0771 - accuracy: 0.9835 - recall_5: 0.9807 - precision_5: 0.9865\n",
      "Epoch 21: val_loss did not improve from 0.24491\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0772 - accuracy: 0.9834 - recall_5: 0.9806 - precision_5: 0.9865 - val_loss: 0.2623 - val_accuracy: 0.9408 - val_recall_5: 0.9315 - val_precision_5: 0.9501\n",
      "Epoch 22/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0628 - accuracy: 0.9887 - recall_5: 0.9857 - precision_5: 0.9909\n",
      "Epoch 22: val_loss improved from 0.24491 to 0.24447, saving model to models\\lstm.h5\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0628 - accuracy: 0.9887 - recall_5: 0.9857 - precision_5: 0.9909 - val_loss: 0.2445 - val_accuracy: 0.9413 - val_recall_5: 0.9353 - val_precision_5: 0.9508\n",
      "Epoch 23/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0740 - accuracy: 0.9856 - recall_5: 0.9824 - precision_5: 0.9883\n",
      "Epoch 23: val_loss improved from 0.24447 to 0.24171, saving model to models\\lstm.h5\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0740 - accuracy: 0.9857 - recall_5: 0.9824 - precision_5: 0.9884 - val_loss: 0.2417 - val_accuracy: 0.9418 - val_recall_5: 0.9337 - val_precision_5: 0.9507\n",
      "Epoch 24/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0610 - accuracy: 0.9886 - recall_5: 0.9863 - precision_5: 0.9910\n",
      "Epoch 24: val_loss improved from 0.24171 to 0.24111, saving model to models\\lstm.h5\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0609 - accuracy: 0.9886 - recall_5: 0.9863 - precision_5: 0.9910 - val_loss: 0.2411 - val_accuracy: 0.9380 - val_recall_5: 0.9299 - val_precision_5: 0.9432\n",
      "Epoch 25/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0602 - accuracy: 0.9889 - recall_5: 0.9862 - precision_5: 0.9907\n",
      "Epoch 25: val_loss improved from 0.24111 to 0.23851, saving model to models\\lstm.h5\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0603 - accuracy: 0.9889 - recall_5: 0.9862 - precision_5: 0.9907 - val_loss: 0.2385 - val_accuracy: 0.9397 - val_recall_5: 0.9304 - val_precision_5: 0.9490\n",
      "Epoch 26/100\n",
      "1038/1038 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9844 - recall_5: 0.9806 - precision_5: 0.9880\n",
      "Epoch 26: val_loss did not improve from 0.23851\n",
      "1038/1038 [==============================] - 17s 16ms/step - loss: 0.0739 - accuracy: 0.9844 - recall_5: 0.9806 - precision_5: 0.9880 - val_loss: 0.2967 - val_accuracy: 0.9315 - val_recall_5: 0.9261 - val_precision_5: 0.9430\n",
      "Epoch 27/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0586 - accuracy: 0.9889 - recall_5: 0.9870 - precision_5: 0.9910\n",
      "Epoch 27: val_loss improved from 0.23851 to 0.23821, saving model to models\\lstm.h5\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0585 - accuracy: 0.9889 - recall_5: 0.9871 - precision_5: 0.9910 - val_loss: 0.2382 - val_accuracy: 0.9467 - val_recall_5: 0.9413 - val_precision_5: 0.9585\n",
      "Epoch 28/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0597 - accuracy: 0.9882 - recall_5: 0.9865 - precision_5: 0.9906\n",
      "Epoch 28: val_loss did not improve from 0.23821\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0601 - accuracy: 0.9881 - recall_5: 0.9864 - precision_5: 0.9905 - val_loss: 0.2565 - val_accuracy: 0.9402 - val_recall_5: 0.9370 - val_precision_5: 0.9504\n",
      "Epoch 29/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0660 - accuracy: 0.9867 - recall_5: 0.9838 - precision_5: 0.9885\n",
      "Epoch 29: val_loss did not improve from 0.23821\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0660 - accuracy: 0.9868 - recall_5: 0.9839 - precision_5: 0.9885 - val_loss: 0.2579 - val_accuracy: 0.9446 - val_recall_5: 0.9380 - val_precision_5: 0.9536\n",
      "Epoch 30/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0537 - accuracy: 0.9898 - recall_5: 0.9881 - precision_5: 0.9918\n",
      "Epoch 30: val_loss did not improve from 0.23821\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0539 - accuracy: 0.9898 - recall_5: 0.9880 - precision_5: 0.9918 - val_loss: 0.2761 - val_accuracy: 0.9364 - val_recall_5: 0.9293 - val_precision_5: 0.9505\n",
      "Epoch 31/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0623 - accuracy: 0.9868 - recall_5: 0.9843 - precision_5: 0.9889\n",
      "Epoch 31: val_loss did not improve from 0.23821\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0622 - accuracy: 0.9868 - recall_5: 0.9843 - precision_5: 0.9889 - val_loss: 0.2980 - val_accuracy: 0.9342 - val_recall_5: 0.9272 - val_precision_5: 0.9431\n",
      "Epoch 32/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0623 - accuracy: 0.9876 - recall_5: 0.9850 - precision_5: 0.9898\n",
      "Epoch 32: val_loss did not improve from 0.23821\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0622 - accuracy: 0.9876 - recall_5: 0.9850 - precision_5: 0.9898 - val_loss: 0.2395 - val_accuracy: 0.9451 - val_recall_5: 0.9418 - val_precision_5: 0.9580\n",
      "Epoch 33/100\n",
      "1035/1038 [============================>.] - ETA: 0s - loss: 0.0501 - accuracy: 0.9909 - recall_5: 0.9890 - precision_5: 0.9924\n",
      "Epoch 33: val_loss did not improve from 0.23821\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0505 - accuracy: 0.9908 - recall_5: 0.9889 - precision_5: 0.9923 - val_loss: 0.2726 - val_accuracy: 0.9348 - val_recall_5: 0.9310 - val_precision_5: 0.9407\n",
      "Epoch 34/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0493 - accuracy: 0.9909 - recall_5: 0.9889 - precision_5: 0.9926\n",
      "Epoch 34: val_loss did not improve from 0.23821\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0493 - accuracy: 0.9909 - recall_5: 0.9889 - precision_5: 0.9926 - val_loss: 0.2955 - val_accuracy: 0.9321 - val_recall_5: 0.9261 - val_precision_5: 0.9435\n",
      "Epoch 35/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0631 - accuracy: 0.9856 - recall_5: 0.9835 - precision_5: 0.9888\n",
      "Epoch 35: val_loss did not improve from 0.23821\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0631 - accuracy: 0.9855 - recall_5: 0.9835 - precision_5: 0.9888 - val_loss: 0.2619 - val_accuracy: 0.9418 - val_recall_5: 0.9364 - val_precision_5: 0.9525\n",
      "Epoch 36/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0533 - accuracy: 0.9904 - recall_5: 0.9880 - precision_5: 0.9918\n",
      "Epoch 36: val_loss did not improve from 0.23821\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0534 - accuracy: 0.9904 - recall_5: 0.9880 - precision_5: 0.9918 - val_loss: 0.2867 - val_accuracy: 0.9342 - val_recall_5: 0.9261 - val_precision_5: 0.9472\n",
      "Epoch 37/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0548 - accuracy: 0.9885 - recall_5: 0.9864 - precision_5: 0.9907\n",
      "Epoch 37: val_loss did not improve from 0.23821\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0548 - accuracy: 0.9886 - recall_5: 0.9865 - precision_5: 0.9907 - val_loss: 0.2476 - val_accuracy: 0.9370 - val_recall_5: 0.9332 - val_precision_5: 0.9497\n",
      "Epoch 38/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0496 - accuracy: 0.9909 - recall_5: 0.9898 - precision_5: 0.9923\n",
      "Epoch 38: val_loss did not improve from 0.23821\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0497 - accuracy: 0.9908 - recall_5: 0.9897 - precision_5: 0.9922 - val_loss: 0.2391 - val_accuracy: 0.9435 - val_recall_5: 0.9375 - val_precision_5: 0.9509\n",
      "Epoch 39/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0510 - accuracy: 0.9897 - recall_5: 0.9885 - precision_5: 0.9909\n",
      "Epoch 39: val_loss did not improve from 0.23821\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0514 - accuracy: 0.9896 - recall_5: 0.9884 - precision_5: 0.9908 - val_loss: 0.2613 - val_accuracy: 0.9391 - val_recall_5: 0.9310 - val_precision_5: 0.9506\n",
      "Epoch 40/100\n",
      "1035/1038 [============================>.] - ETA: 0s - loss: 0.0591 - accuracy: 0.9873 - recall_5: 0.9853 - precision_5: 0.9892\n",
      "Epoch 40: val_loss did not improve from 0.23821\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0590 - accuracy: 0.9874 - recall_5: 0.9854 - precision_5: 0.9892 - val_loss: 0.2603 - val_accuracy: 0.9440 - val_recall_5: 0.9424 - val_precision_5: 0.9491\n",
      "Epoch 41/100\n",
      "1035/1038 [============================>.] - ETA: 0s - loss: 0.0541 - accuracy: 0.9886 - recall_5: 0.9867 - precision_5: 0.9905\n",
      "Epoch 41: val_loss did not improve from 0.23821\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0540 - accuracy: 0.9886 - recall_5: 0.9867 - precision_5: 0.9906 - val_loss: 0.2697 - val_accuracy: 0.9364 - val_recall_5: 0.9337 - val_precision_5: 0.9450\n",
      "Epoch 42/100\n",
      "1035/1038 [============================>.] - ETA: 0s - loss: 0.0396 - accuracy: 0.9934 - recall_5: 0.9923 - precision_5: 0.9947\n",
      "Epoch 42: val_loss improved from 0.23821 to 0.21695, saving model to models\\lstm.h5\n",
      "1038/1038 [==============================] - 17s 16ms/step - loss: 0.0396 - accuracy: 0.9934 - recall_5: 0.9923 - precision_5: 0.9947 - val_loss: 0.2170 - val_accuracy: 0.9478 - val_recall_5: 0.9435 - val_precision_5: 0.9570\n",
      "Epoch 43/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0523 - accuracy: 0.9895 - recall_5: 0.9881 - precision_5: 0.9911\n",
      "Epoch 43: val_loss did not improve from 0.21695\n",
      "1038/1038 [==============================] - 17s 16ms/step - loss: 0.0523 - accuracy: 0.9895 - recall_5: 0.9881 - precision_5: 0.9911 - val_loss: 0.2434 - val_accuracy: 0.9429 - val_recall_5: 0.9359 - val_precision_5: 0.9519\n",
      "Epoch 44/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 0.9903 - recall_5: 0.9879 - precision_5: 0.9917\n",
      "Epoch 44: val_loss did not improve from 0.21695\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0520 - accuracy: 0.9903 - recall_5: 0.9880 - precision_5: 0.9917 - val_loss: 0.2270 - val_accuracy: 0.9446 - val_recall_5: 0.9397 - val_precision_5: 0.9563\n",
      "Epoch 45/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0480 - accuracy: 0.9907 - recall_5: 0.9894 - precision_5: 0.9921\n",
      "Epoch 45: val_loss did not improve from 0.21695\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0480 - accuracy: 0.9907 - recall_5: 0.9894 - precision_5: 0.9921 - val_loss: 0.2509 - val_accuracy: 0.9408 - val_recall_5: 0.9342 - val_precision_5: 0.9492\n",
      "Epoch 46/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0438 - accuracy: 0.9925 - recall_5: 0.9910 - precision_5: 0.9940\n",
      "Epoch 46: val_loss did not improve from 0.21695\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0438 - accuracy: 0.9924 - recall_5: 0.9909 - precision_5: 0.9940 - val_loss: 0.2553 - val_accuracy: 0.9342 - val_recall_5: 0.9299 - val_precision_5: 0.9432\n",
      "Epoch 47/100\n",
      "1035/1038 [============================>.] - ETA: 0s - loss: 0.0575 - accuracy: 0.9882 - recall_5: 0.9864 - precision_5: 0.9902\n",
      "Epoch 47: val_loss did not improve from 0.21695\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0576 - accuracy: 0.9881 - recall_5: 0.9862 - precision_5: 0.9901 - val_loss: 0.3049 - val_accuracy: 0.9310 - val_recall_5: 0.9266 - val_precision_5: 0.9399\n",
      "Epoch 48/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0596 - accuracy: 0.9878 - recall_5: 0.9863 - precision_5: 0.9894\n",
      "Epoch 48: val_loss did not improve from 0.21695\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0596 - accuracy: 0.9878 - recall_5: 0.9863 - precision_5: 0.9894 - val_loss: 0.2392 - val_accuracy: 0.9429 - val_recall_5: 0.9397 - val_precision_5: 0.9531\n",
      "Epoch 49/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0371 - accuracy: 0.9941 - recall_5: 0.9929 - precision_5: 0.9951\n",
      "Epoch 49: val_loss did not improve from 0.21695\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0371 - accuracy: 0.9941 - recall_5: 0.9930 - precision_5: 0.9951 - val_loss: 0.2488 - val_accuracy: 0.9451 - val_recall_5: 0.9402 - val_precision_5: 0.9537\n",
      "Epoch 50/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0455 - accuracy: 0.9904 - recall_5: 0.9890 - precision_5: 0.9917\n",
      "Epoch 50: val_loss did not improve from 0.21695\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0455 - accuracy: 0.9904 - recall_5: 0.9890 - precision_5: 0.9917 - val_loss: 0.2601 - val_accuracy: 0.9418 - val_recall_5: 0.9370 - val_precision_5: 0.9499\n",
      "Epoch 51/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0528 - accuracy: 0.9889 - recall_5: 0.9872 - precision_5: 0.9907\n",
      "Epoch 51: val_loss did not improve from 0.21695\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0528 - accuracy: 0.9889 - recall_5: 0.9872 - precision_5: 0.9907 - val_loss: 0.2360 - val_accuracy: 0.9435 - val_recall_5: 0.9380 - val_precision_5: 0.9536\n",
      "Epoch 52/100\n",
      "1035/1038 [============================>.] - ETA: 0s - loss: 0.0448 - accuracy: 0.9915 - recall_5: 0.9900 - precision_5: 0.9935\n",
      "Epoch 52: val_loss did not improve from 0.21695\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0447 - accuracy: 0.9916 - recall_5: 0.9901 - precision_5: 0.9935 - val_loss: 0.2383 - val_accuracy: 0.9397 - val_recall_5: 0.9364 - val_precision_5: 0.9488\n",
      "Epoch 53/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9922 - recall_5: 0.9908 - precision_5: 0.9933\n",
      "Epoch 53: val_loss did not improve from 0.21695\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0420 - accuracy: 0.9922 - recall_5: 0.9908 - precision_5: 0.9934 - val_loss: 0.2295 - val_accuracy: 0.9511 - val_recall_5: 0.9473 - val_precision_5: 0.9572\n",
      "Epoch 54/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9926 - recall_5: 0.9916 - precision_5: 0.9936\n",
      "Epoch 54: val_loss did not improve from 0.21695\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0402 - accuracy: 0.9927 - recall_5: 0.9916 - precision_5: 0.9936 - val_loss: 0.2630 - val_accuracy: 0.9429 - val_recall_5: 0.9375 - val_precision_5: 0.9557\n",
      "Epoch 55/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9939 - recall_5: 0.9926 - precision_5: 0.9947\n",
      "Epoch 55: val_loss did not improve from 0.21695\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0373 - accuracy: 0.9939 - recall_5: 0.9927 - precision_5: 0.9948 - val_loss: 0.2628 - val_accuracy: 0.9413 - val_recall_5: 0.9375 - val_precision_5: 0.9509\n",
      "Epoch 56/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0508 - accuracy: 0.9893 - recall_5: 0.9872 - precision_5: 0.9904\n",
      "Epoch 56: val_loss did not improve from 0.21695\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0509 - accuracy: 0.9892 - recall_5: 0.9872 - precision_5: 0.9904 - val_loss: 0.2538 - val_accuracy: 0.9457 - val_recall_5: 0.9429 - val_precision_5: 0.9543\n",
      "Epoch 57/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 0.9892 - recall_5: 0.9875 - precision_5: 0.9903\n",
      "Epoch 57: val_loss did not improve from 0.21695\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0537 - accuracy: 0.9892 - recall_5: 0.9875 - precision_5: 0.9903 - val_loss: 0.2553 - val_accuracy: 0.9435 - val_recall_5: 0.9391 - val_precision_5: 0.9500\n",
      "Epoch 58/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0377 - accuracy: 0.9934 - recall_5: 0.9925 - precision_5: 0.9943\n",
      "Epoch 58: val_loss improved from 0.21695 to 0.21663, saving model to models\\lstm.h5\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0377 - accuracy: 0.9934 - recall_5: 0.9925 - precision_5: 0.9943 - val_loss: 0.2166 - val_accuracy: 0.9484 - val_recall_5: 0.9435 - val_precision_5: 0.9565\n",
      "Epoch 59/100\n",
      "1035/1038 [============================>.] - ETA: 0s - loss: 0.0486 - accuracy: 0.9897 - recall_5: 0.9885 - precision_5: 0.9914\n",
      "Epoch 59: val_loss did not improve from 0.21663\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0486 - accuracy: 0.9896 - recall_5: 0.9885 - precision_5: 0.9914 - val_loss: 0.2758 - val_accuracy: 0.9413 - val_recall_5: 0.9337 - val_precision_5: 0.9497\n",
      "Epoch 60/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0461 - accuracy: 0.9906 - recall_5: 0.9893 - precision_5: 0.9916\n",
      "Epoch 60: val_loss did not improve from 0.21663\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0461 - accuracy: 0.9906 - recall_5: 0.9893 - precision_5: 0.9916 - val_loss: 0.2419 - val_accuracy: 0.9527 - val_recall_5: 0.9489 - val_precision_5: 0.9599\n",
      "Epoch 61/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0389 - accuracy: 0.9928 - recall_5: 0.9919 - precision_5: 0.9937\n",
      "Epoch 61: val_loss improved from 0.21663 to 0.21064, saving model to models\\lstm.h5\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0389 - accuracy: 0.9928 - recall_5: 0.9919 - precision_5: 0.9937 - val_loss: 0.2106 - val_accuracy: 0.9527 - val_recall_5: 0.9467 - val_precision_5: 0.9598\n",
      "Epoch 62/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0464 - accuracy: 0.9908 - recall_5: 0.9897 - precision_5: 0.9923\n",
      "Epoch 62: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0464 - accuracy: 0.9908 - recall_5: 0.9897 - precision_5: 0.9923 - val_loss: 0.2519 - val_accuracy: 0.9473 - val_recall_5: 0.9429 - val_precision_5: 0.9533\n",
      "Epoch 63/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0456 - accuracy: 0.9914 - recall_5: 0.9896 - precision_5: 0.9926\n",
      "Epoch 63: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0455 - accuracy: 0.9914 - recall_5: 0.9896 - precision_5: 0.9926 - val_loss: 0.2678 - val_accuracy: 0.9440 - val_recall_5: 0.9418 - val_precision_5: 0.9512\n",
      "Epoch 64/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0363 - accuracy: 0.9934 - recall_5: 0.9925 - precision_5: 0.9946\n",
      "Epoch 64: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0363 - accuracy: 0.9934 - recall_5: 0.9925 - precision_5: 0.9946 - val_loss: 0.2345 - val_accuracy: 0.9478 - val_recall_5: 0.9457 - val_precision_5: 0.9587\n",
      "Epoch 65/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0382 - accuracy: 0.9931 - recall_5: 0.9918 - precision_5: 0.9937\n",
      "Epoch 65: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0382 - accuracy: 0.9931 - recall_5: 0.9918 - precision_5: 0.9937 - val_loss: 0.2611 - val_accuracy: 0.9418 - val_recall_5: 0.9380 - val_precision_5: 0.9531\n",
      "Epoch 66/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0515 - accuracy: 0.9882 - recall_5: 0.9873 - precision_5: 0.9905\n",
      "Epoch 66: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0514 - accuracy: 0.9883 - recall_5: 0.9873 - precision_5: 0.9905 - val_loss: 0.2846 - val_accuracy: 0.9484 - val_recall_5: 0.9408 - val_precision_5: 0.9542\n",
      "Epoch 67/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0439 - accuracy: 0.9915 - recall_5: 0.9902 - precision_5: 0.9924\n",
      "Epoch 67: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0439 - accuracy: 0.9915 - recall_5: 0.9902 - precision_5: 0.9925 - val_loss: 0.2646 - val_accuracy: 0.9489 - val_recall_5: 0.9440 - val_precision_5: 0.9570\n",
      "Epoch 68/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0416 - accuracy: 0.9920 - recall_5: 0.9908 - precision_5: 0.9933\n",
      "Epoch 68: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0415 - accuracy: 0.9920 - recall_5: 0.9908 - precision_5: 0.9933 - val_loss: 0.2806 - val_accuracy: 0.9397 - val_recall_5: 0.9364 - val_precision_5: 0.9472\n",
      "Epoch 69/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9934 - recall_5: 0.9929 - precision_5: 0.9943\n",
      "Epoch 69: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0343 - accuracy: 0.9934 - recall_5: 0.9930 - precision_5: 0.9943 - val_loss: 0.2570 - val_accuracy: 0.9462 - val_recall_5: 0.9435 - val_precision_5: 0.9544\n",
      "Epoch 70/100\n",
      "1035/1038 [============================>.] - ETA: 0s - loss: 0.0445 - accuracy: 0.9910 - recall_5: 0.9898 - precision_5: 0.9926\n",
      "Epoch 70: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0445 - accuracy: 0.9910 - recall_5: 0.9898 - precision_5: 0.9926 - val_loss: 0.2883 - val_accuracy: 0.9457 - val_recall_5: 0.9429 - val_precision_5: 0.9512\n",
      "Epoch 71/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0379 - accuracy: 0.9928 - recall_5: 0.9916 - precision_5: 0.9938\n",
      "Epoch 71: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0379 - accuracy: 0.9928 - recall_5: 0.9916 - precision_5: 0.9938 - val_loss: 0.2711 - val_accuracy: 0.9462 - val_recall_5: 0.9413 - val_precision_5: 0.9527\n",
      "Epoch 72/100\n",
      "1035/1038 [============================>.] - ETA: 0s - loss: 0.0485 - accuracy: 0.9893 - recall_5: 0.9880 - precision_5: 0.9911\n",
      "Epoch 72: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0484 - accuracy: 0.9893 - recall_5: 0.9881 - precision_5: 0.9911 - val_loss: 0.2608 - val_accuracy: 0.9440 - val_recall_5: 0.9402 - val_precision_5: 0.9521\n",
      "Epoch 73/100\n",
      "1035/1038 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9935 - recall_5: 0.9925 - precision_5: 0.9942\n",
      "Epoch 73: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0352 - accuracy: 0.9934 - recall_5: 0.9925 - precision_5: 0.9941 - val_loss: 0.2640 - val_accuracy: 0.9429 - val_recall_5: 0.9418 - val_precision_5: 0.9460\n",
      "Epoch 74/100\n",
      "1035/1038 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9938 - recall_5: 0.9926 - precision_5: 0.9946\n",
      "Epoch 74: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0338 - accuracy: 0.9938 - recall_5: 0.9927 - precision_5: 0.9946 - val_loss: 0.2699 - val_accuracy: 0.9435 - val_recall_5: 0.9397 - val_precision_5: 0.9531\n",
      "Epoch 75/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9935 - recall_5: 0.9923 - precision_5: 0.9944\n",
      "Epoch 75: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0350 - accuracy: 0.9935 - recall_5: 0.9924 - precision_5: 0.9944 - val_loss: 0.2338 - val_accuracy: 0.9495 - val_recall_5: 0.9440 - val_precision_5: 0.9570\n",
      "Epoch 76/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy: 0.9927 - recall_5: 0.9919 - precision_5: 0.9935\n",
      "Epoch 76: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0341 - accuracy: 0.9927 - recall_5: 0.9919 - precision_5: 0.9935 - val_loss: 0.2735 - val_accuracy: 0.9451 - val_recall_5: 0.9397 - val_precision_5: 0.9547\n",
      "Epoch 77/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0434 - accuracy: 0.9910 - recall_5: 0.9897 - precision_5: 0.9923\n",
      "Epoch 77: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0437 - accuracy: 0.9908 - recall_5: 0.9896 - precision_5: 0.9922 - val_loss: 0.2849 - val_accuracy: 0.9342 - val_recall_5: 0.9304 - val_precision_5: 0.9417\n",
      "Epoch 78/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0365 - accuracy: 0.9929 - recall_5: 0.9924 - precision_5: 0.9938\n",
      "Epoch 78: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0365 - accuracy: 0.9930 - recall_5: 0.9924 - precision_5: 0.9938 - val_loss: 0.2893 - val_accuracy: 0.9397 - val_recall_5: 0.9359 - val_precision_5: 0.9467\n",
      "Epoch 79/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0406 - accuracy: 0.9919 - recall_5: 0.9909 - precision_5: 0.9928\n",
      "Epoch 79: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0406 - accuracy: 0.9919 - recall_5: 0.9909 - precision_5: 0.9928 - val_loss: 0.2712 - val_accuracy: 0.9424 - val_recall_5: 0.9391 - val_precision_5: 0.9500\n",
      "Epoch 80/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0435 - accuracy: 0.9912 - recall_5: 0.9901 - precision_5: 0.9924\n",
      "Epoch 80: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0434 - accuracy: 0.9912 - recall_5: 0.9901 - precision_5: 0.9925 - val_loss: 0.2737 - val_accuracy: 0.9435 - val_recall_5: 0.9397 - val_precision_5: 0.9521\n",
      "Epoch 81/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0374 - accuracy: 0.9924 - recall_5: 0.9913 - precision_5: 0.9937\n",
      "Epoch 81: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0373 - accuracy: 0.9924 - recall_5: 0.9913 - precision_5: 0.9937 - val_loss: 0.2843 - val_accuracy: 0.9424 - val_recall_5: 0.9375 - val_precision_5: 0.9468\n",
      "Epoch 82/100\n",
      "1035/1038 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9940 - recall_5: 0.9927 - precision_5: 0.9947\n",
      "Epoch 82: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0351 - accuracy: 0.9940 - recall_5: 0.9927 - precision_5: 0.9947 - val_loss: 0.2792 - val_accuracy: 0.9418 - val_recall_5: 0.9342 - val_precision_5: 0.9482\n",
      "Epoch 83/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9938 - recall_5: 0.9933 - precision_5: 0.9946\n",
      "Epoch 83: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0350 - accuracy: 0.9938 - recall_5: 0.9933 - precision_5: 0.9946 - val_loss: 0.2775 - val_accuracy: 0.9391 - val_recall_5: 0.9337 - val_precision_5: 0.9492\n",
      "Epoch 84/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0386 - accuracy: 0.9919 - recall_5: 0.9905 - precision_5: 0.9929\n",
      "Epoch 84: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0388 - accuracy: 0.9918 - recall_5: 0.9905 - precision_5: 0.9928 - val_loss: 0.2971 - val_accuracy: 0.9386 - val_recall_5: 0.9326 - val_precision_5: 0.9455\n",
      "Epoch 85/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0512 - accuracy: 0.9893 - recall_5: 0.9876 - precision_5: 0.9909\n",
      "Epoch 85: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0512 - accuracy: 0.9893 - recall_5: 0.9876 - precision_5: 0.9909 - val_loss: 0.2635 - val_accuracy: 0.9397 - val_recall_5: 0.9359 - val_precision_5: 0.9498\n",
      "Epoch 86/100\n",
      "1035/1038 [============================>.] - ETA: 0s - loss: 0.0333 - accuracy: 0.9946 - recall_5: 0.9937 - precision_5: 0.9955\n",
      "Epoch 86: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0332 - accuracy: 0.9946 - recall_5: 0.9937 - precision_5: 0.9955 - val_loss: 0.2613 - val_accuracy: 0.9473 - val_recall_5: 0.9440 - val_precision_5: 0.9539\n",
      "Epoch 87/100\n",
      "1035/1038 [============================>.] - ETA: 0s - loss: 0.0463 - accuracy: 0.9907 - recall_5: 0.9897 - precision_5: 0.9920\n",
      "Epoch 87: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0463 - accuracy: 0.9907 - recall_5: 0.9897 - precision_5: 0.9920 - val_loss: 0.2673 - val_accuracy: 0.9473 - val_recall_5: 0.9397 - val_precision_5: 0.9531\n",
      "Epoch 88/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0358 - accuracy: 0.9935 - recall_5: 0.9923 - precision_5: 0.9945\n",
      "Epoch 88: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0357 - accuracy: 0.9935 - recall_5: 0.9924 - precision_5: 0.9945 - val_loss: 0.2472 - val_accuracy: 0.9473 - val_recall_5: 0.9435 - val_precision_5: 0.9528\n",
      "Epoch 89/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0333 - accuracy: 0.9950 - recall_5: 0.9936 - precision_5: 0.9956\n",
      "Epoch 89: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0333 - accuracy: 0.9950 - recall_5: 0.9936 - precision_5: 0.9956 - val_loss: 0.2495 - val_accuracy: 0.9457 - val_recall_5: 0.9429 - val_precision_5: 0.9533\n",
      "Epoch 90/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0396 - accuracy: 0.9929 - recall_5: 0.9919 - precision_5: 0.9940\n",
      "Epoch 90: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0396 - accuracy: 0.9929 - recall_5: 0.9919 - precision_5: 0.9940 - val_loss: 0.2917 - val_accuracy: 0.9473 - val_recall_5: 0.9413 - val_precision_5: 0.9569\n",
      "Epoch 91/100\n",
      "1035/1038 [============================>.] - ETA: 0s - loss: 0.0341 - accuracy: 0.9931 - recall_5: 0.9925 - precision_5: 0.9944\n",
      "Epoch 91: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0341 - accuracy: 0.9931 - recall_5: 0.9925 - precision_5: 0.9944 - val_loss: 0.2765 - val_accuracy: 0.9440 - val_recall_5: 0.9397 - val_precision_5: 0.9495\n",
      "Epoch 92/100\n",
      "1038/1038 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 0.9931 - recall_5: 0.9918 - precision_5: 0.9940\n",
      "Epoch 92: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0366 - accuracy: 0.9931 - recall_5: 0.9918 - precision_5: 0.9940 - val_loss: 0.2880 - val_accuracy: 0.9467 - val_recall_5: 0.9446 - val_precision_5: 0.9544\n",
      "Epoch 93/100\n",
      "1035/1038 [============================>.] - ETA: 0s - loss: 0.0348 - accuracy: 0.9935 - recall_5: 0.9922 - precision_5: 0.9949\n",
      "Epoch 93: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0348 - accuracy: 0.9935 - recall_5: 0.9922 - precision_5: 0.9949 - val_loss: 0.2908 - val_accuracy: 0.9457 - val_recall_5: 0.9424 - val_precision_5: 0.9543\n",
      "Epoch 94/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0502 - accuracy: 0.9893 - recall_5: 0.9881 - precision_5: 0.9902\n",
      "Epoch 94: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 15ms/step - loss: 0.0502 - accuracy: 0.9893 - recall_5: 0.9881 - precision_5: 0.9902 - val_loss: 0.2963 - val_accuracy: 0.9435 - val_recall_5: 0.9386 - val_precision_5: 0.9510\n",
      "Epoch 95/100\n",
      "1035/1038 [============================>.] - ETA: 0s - loss: 0.0404 - accuracy: 0.9919 - recall_5: 0.9909 - precision_5: 0.9932\n",
      "Epoch 95: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0403 - accuracy: 0.9919 - recall_5: 0.9910 - precision_5: 0.9932 - val_loss: 0.2472 - val_accuracy: 0.9505 - val_recall_5: 0.9462 - val_precision_5: 0.9561\n",
      "Epoch 96/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0363 - accuracy: 0.9931 - recall_5: 0.9922 - precision_5: 0.9940\n",
      "Epoch 96: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0364 - accuracy: 0.9931 - recall_5: 0.9922 - precision_5: 0.9939 - val_loss: 0.3300 - val_accuracy: 0.9255 - val_recall_5: 0.9207 - val_precision_5: 0.9375\n",
      "Epoch 97/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0459 - accuracy: 0.9905 - recall_5: 0.9893 - precision_5: 0.9921\n",
      "Epoch 97: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0458 - accuracy: 0.9905 - recall_5: 0.9893 - precision_5: 0.9921 - val_loss: 0.3000 - val_accuracy: 0.9478 - val_recall_5: 0.9446 - val_precision_5: 0.9513\n",
      "Epoch 98/100\n",
      "1036/1038 [============================>.] - ETA: 0s - loss: 0.0365 - accuracy: 0.9927 - recall_5: 0.9917 - precision_5: 0.9937\n",
      "Epoch 98: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0365 - accuracy: 0.9927 - recall_5: 0.9918 - precision_5: 0.9937 - val_loss: 0.3139 - val_accuracy: 0.9353 - val_recall_5: 0.9272 - val_precision_5: 0.9457\n",
      "Epoch 99/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0393 - accuracy: 0.9925 - recall_5: 0.9910 - precision_5: 0.9937\n",
      "Epoch 99: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0393 - accuracy: 0.9925 - recall_5: 0.9910 - precision_5: 0.9937 - val_loss: 0.2954 - val_accuracy: 0.9424 - val_recall_5: 0.9380 - val_precision_5: 0.9494\n",
      "Epoch 100/100\n",
      "1037/1038 [============================>.] - ETA: 0s - loss: 0.0419 - accuracy: 0.9913 - recall_5: 0.9906 - precision_5: 0.9921\n",
      "Epoch 100: val_loss did not improve from 0.21064\n",
      "1038/1038 [==============================] - 16s 16ms/step - loss: 0.0419 - accuracy: 0.9913 - recall_5: 0.9906 - precision_5: 0.9921 - val_loss: 0.3388 - val_accuracy: 0.9332 - val_recall_5: 0.9255 - val_precision_5: 0.9409\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from models import Conv1D, Conv2D, LSTM\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import argparse\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, wav_paths, labels, sr, dt, n_classes,\n",
    "                 batch_size=32, shuffle=True):\n",
    "        self.wav_paths = wav_paths\n",
    "        self.labels = labels\n",
    "        self.sr = sr\n",
    "        self.dt = dt\n",
    "        self.n_classes = n_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = True\n",
    "        self.on_epoch_end()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.wav_paths) / self.batch_size)) #total number of files divided by batch size\n",
    "\n",
    "    #iter will call __getitem__\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        wav_paths = [self.wav_paths[k] for k in indexes]\n",
    "        labels = [self.labels[k] for k in indexes]\n",
    "\n",
    "        # generate a batch of time data\n",
    "        X = np.empty((self.batch_size, int(self.sr*self.dt), 1), dtype=np.float32)\n",
    "        Y = np.empty((self.batch_size, self.n_classes), dtype=np.float32)\n",
    "\n",
    "        for i, (path, label) in enumerate(zip(wav_paths, labels)):\n",
    "            rate, wav = wavfile.read(path)\n",
    "            X[i,] = wav.reshape(-1, 1)\n",
    "            Y[i,] = to_categorical(label, num_classes=self.n_classes)\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.wav_paths))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    src_root = args.src_root\n",
    "    sr = args.sample_rate\n",
    "    dt = args.delta_time\n",
    "    batch_size = args.batch_size\n",
    "    model_type = args.model_type\n",
    "    params = {'N_CLASSES':len(os.listdir(args.src_root)),\n",
    "              'SR':sr,\n",
    "              'DT':dt}\n",
    "    models = {'conv1d':Conv1D(**params),\n",
    "              'conv2d':Conv2D(**params),\n",
    "              'lstm':  LSTM(**params)}\n",
    "    assert model_type in models.keys(), '{} not an available model'.format(model_type)\n",
    "    csv_path = os.path.join('logs', '{}_history.csv'.format(model_type))\n",
    "\n",
    "    wav_paths = glob('{}/**'.format(src_root), recursive=True)\n",
    "    wav_paths = [x.replace(os.sep, '/') for x in wav_paths if '.wav' in x] #replace the separator symbol to /\n",
    "    classes = sorted(os.listdir(args.src_root))\n",
    "    le = LabelEncoder()\n",
    "    le.fit(classes)\n",
    "    labels = [os.path.split(x)[0].split('/')[-1] for x in wav_paths]\n",
    "    labels = le.transform(labels)\n",
    "    wav_train, wav_val, label_train, label_val = train_test_split(wav_paths,\n",
    "                                                                  labels,\n",
    "                                                                  test_size=0.1,\n",
    "                                                                  random_state=0)\n",
    "\n",
    "    assert len(label_train) >= args.batch_size, 'Number of train samples must be >= batch_size'\n",
    "    if len(set(label_train)) != params['N_CLASSES']:\n",
    "        warnings.warn('Found {}/{} classes in training data. Increase data size or change random_state.'.format(len(set(label_train)), params['N_CLASSES']))\n",
    "    if len(set(label_val)) != params['N_CLASSES']:\n",
    "        warnings.warn('Found {}/{} classes in validation data. Increase data size or change random_state.'.format(len(set(label_val)), params['N_CLASSES']))\n",
    "\n",
    "    tg = DataGenerator(wav_train, label_train, sr, dt,\n",
    "                       params['N_CLASSES'], batch_size=batch_size)\n",
    "    vg = DataGenerator(wav_val, label_val, sr, dt,\n",
    "                       params['N_CLASSES'], batch_size=batch_size)\n",
    "    \n",
    "    \n",
    "    #model = models[model_type]\n",
    "    #model.summary()\n",
    "\n",
    "    #'''\n",
    "    model = models[model_type]\n",
    "    model.summary()\n",
    "    cp = ModelCheckpoint('models/{}.h5'.format(model_type), monitor='val_loss',\n",
    "                         save_best_only=True, save_weights_only=False,\n",
    "                         mode='auto', save_freq='epoch', verbose=1)\n",
    "    csv_logger = CSVLogger(csv_path, append=False)\n",
    "    hist = model.fit(tg, validation_data=vg,\n",
    "              epochs=100, verbose=1,\n",
    "              callbacks=[csv_logger, cp])\n",
    "    #'''\n",
    "    return hist\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Audio Classification Training')\n",
    "    parser.add_argument('--model_type', type=str, default='lstm',\n",
    "                        help='model to run. i.e. conv1d, conv2d, lstm')\n",
    "    parser.add_argument('--src_root', type=str, default='D:/SirenNeuralNetwork/Audio-Classification/clean',\n",
    "                        help='directory of audio files in total duration')\n",
    "    parser.add_argument('--batch_size', type=int, default=16,\n",
    "                        help='batch size')\n",
    "    parser.add_argument('--delta_time', '-dt', type=float, default=1.0,\n",
    "                        help='time in seconds to sample audio')\n",
    "    parser.add_argument('--sample_rate', '-sr', type=int, default=16000,\n",
    "                        help='sample rate of clean audio')\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    hist = train(args)\n",
    "\n",
    "# python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\SirenNeuralNetwork\\Audio-Classification\\train.ipynb Cell 2\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SirenNeuralNetwork/Audio-Classification/train.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/SirenNeuralNetwork/Audio-Classification/train.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(hist\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SirenNeuralNetwork/Audio-Classification/train.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(hist\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalidation accuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SirenNeuralNetwork/Audio-Classification/train.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mlegend()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.plot(hist.history['accuracy'], 'r', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], 'b', label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Loss')\n",
    "plt.plot(hist.history['loss'], 'r', label='loss')\n",
    "plt.plot(hist.history['val_loss'], 'b', label='validation loss')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Precision')\n",
    "plt.plot(hist.history['precision'], 'r', label='precision')\n",
    "plt.plot(hist.history['val_precision'], 'b', label='validation precision')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Recall')\n",
    "plt.plot(hist.history['recall'], 'r', label='recall')\n",
    "plt.plot(hist.history['val_recall'], 'b', label='validation recall')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siren",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
